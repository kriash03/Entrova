{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Influencer_ID         0\n",
      "Name                  0\n",
      "Platform              0\n",
      "Followers             0\n",
      "Engagement_Rate       0\n",
      "Niche                 0\n",
      "Avg_Likes             0\n",
      "Avg_Comments          0\n",
      "Audience_Age          0\n",
      "Audience_Location     0\n",
      "Past_Brand_Collabs    0\n",
      "Fraud_Score           0\n",
      "Male_Percentage       0\n",
      "Female_Percentage     0\n",
      "dtype: int64\n",
      "   Influencer_ID          Name   Platform  Followers  Engagement_Rate  \\\n",
      "0              1  Influencer_1     TikTok     765340             6.18   \n",
      "1              2  Influencer_2  Instagram     270668             4.82   \n",
      "2              3  Influencer_3     TikTok     352022             2.63   \n",
      "3              4  Influencer_4  Instagram     983553             5.61   \n",
      "4              5  Influencer_5    YouTube     315287             6.74   \n",
      "\n",
      "     Niche  Avg_Likes  Avg_Comments Audience_Age Audience_Location  \\\n",
      "0  Fashion      47298          2252        23-41                UK   \n",
      "1    Music      13046           931        29-44         Australia   \n",
      "2  Finance       9258           841        26-32           Germany   \n",
      "3     Tech      55177          2758        26-44            Canada   \n",
      "4  Fashion      21250           965        28-44            Brazil   \n",
      "\n",
      "      Past_Brand_Collabs  Fraud_Score  Male_Percentage  Female_Percentage  \n",
      "0    Zara, L'Oreal, Nike            1             67.0               53.0  \n",
      "1   Samsung, Tesla, Nike            3             51.0               52.0  \n",
      "2              Uber Eats            4             60.0               19.0  \n",
      "3  Uber Eats, Apple, H&M            8             60.0               23.0  \n",
      "4          Zara, Samsung            4             81.0               44.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('sample_influencer_database_large.csv')\n",
    "\n",
    "# Improved function to extract percentages\n",
    "def extract_percentages(gender_str):\n",
    "    try:\n",
    "        # Split by comma to separate male and female parts\n",
    "        parts = gender_str.split(',')\n",
    "        \n",
    "        # Extract male percentage from first part\n",
    "        male_part = parts[0].strip()  # \"XX% Male\"\n",
    "        male_percentage = float(male_part.split('%')[0])\n",
    "        \n",
    "        # Extract female percentage from second part\n",
    "        female_part = parts[1].strip()  # \"YY% Female\"\n",
    "        female_percentage = float(female_part.split('%')[0])\n",
    "        \n",
    "        return male_percentage, female_percentage\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing: '{gender_str}'. Error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# Apply the function to create new columns\n",
    "df[['Male_Percentage', 'Female_Percentage']] = df['Audience_Gender'].apply(\n",
    "    lambda x: pd.Series(extract_percentages(x))\n",
    ")\n",
    "\n",
    "# Drop the original Audience_Gender column\n",
    "df.drop(columns=['Audience_Gender'], inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_influencer_data.csv', index=False)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Analysis Results with VADER:\n",
      "   Influencer_ID                 Post_Caption  Caption_Sentiment_VADER  \\\n",
      "0              1  Check out my new outfit! üõçÔ∏è                   0.0000   \n",
      "1              2  Just dropped a new track! üé∂                   0.0000   \n",
      "2              3       5 tips to save money üí∞                   0.4939   \n",
      "\n",
      "                                Comments  Comments_Sentiment_VADER  \n",
      "0  Love this look! üòç, Where‚Äôs this from?                    0.8172  \n",
      "1      Fire! üî•, Can‚Äôt wait to hear more!                   -0.6580  \n",
      "2           Great advice!, Very helpful!                    0.8306  \n",
      "\n",
      "Most common hashtags:\n",
      "[('#fashion', 1), ('#ootd', 1), ('#style', 1), ('#music', 1), ('#newrelease', 1), ('#hiphop', 1), ('#finance', 1), ('#savings', 1), ('#money', 1)]\n"
     ]
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from collections import Counter\n",
    "\n",
    "# Sample data with Hashtags\n",
    "data = {\n",
    "    \"Influencer_ID\": [1, 2, 3],\n",
    "    \"Post_Caption\": [\n",
    "        \"Check out my new outfit! üõçÔ∏è\",\n",
    "        \"Just dropped a new track! üé∂\",\n",
    "        \"5 tips to save money üí∞\"\n",
    "    ],\n",
    "    \"Hashtags\": [\n",
    "        \"#fashion #ootd #style\",\n",
    "        \"#music #newrelease #hiphop\",\n",
    "        \"#finance #savings #money\"\n",
    "    ],\n",
    "    \"Comments\": [\n",
    "        \"Love this look! üòç, Where‚Äôs this from?\",\n",
    "        \"Fire! üî•, Can‚Äôt wait to hear more!\",\n",
    "        \"Great advice!, Very helpful!\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_posts = pd.DataFrame(data)\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to analyze sentiment using VADER\n",
    "def analyze_sentiment_vader(text):\n",
    "    return analyzer.polarity_scores(text)['compound']  # Returns a score between -1 (negative) and 1 (positive)\n",
    "\n",
    "# Analyze sentiment for captions using VADER\n",
    "df_posts['Caption_Sentiment_VADER'] = df_posts['Post_Caption'].apply(analyze_sentiment_vader)\n",
    "\n",
    "# Analyze sentiment for comments using VADER\n",
    "df_posts['Comments_Sentiment_VADER'] = df_posts['Comments'].apply(analyze_sentiment_vader)\n",
    "\n",
    "# Display the results\n",
    "print(\"Sentiment Analysis Results with VADER:\")\n",
    "print(df_posts[['Influencer_ID', 'Post_Caption', 'Caption_Sentiment_VADER', 'Comments', 'Comments_Sentiment_VADER']])\n",
    "\n",
    "# Extract hashtags from the sample data\n",
    "hashtags = []\n",
    "for tags in df_posts['Hashtags']:\n",
    "    hashtags.extend(tags.split())\n",
    "\n",
    "# Count the frequency of each hashtag\n",
    "hashtag_freq = Counter(hashtags)\n",
    "\n",
    "# Display the most common hashtags\n",
    "print(\"\\nMost common hashtags:\")\n",
    "print(hashtag_freq.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Influencer_ID           Name  Engagement_Rate  Audience_Match_Score  \\\n",
      "94             95  Influencer_95             8.14             90.000000   \n",
      "9              10  Influencer_10             8.93             95.000000   \n",
      "88             89  Influencer_89             7.89             62.000000   \n",
      "5               6   Influencer_6             8.99             56.333333   \n",
      "84             85  Influencer_85             7.49             97.666667   \n",
      "0               1   Influencer_1             6.18             64.333333   \n",
      "87             88  Influencer_88             8.24             61.333333   \n",
      "66             67  Influencer_67             8.83             60.333333   \n",
      "71             72  Influencer_72             6.01             62.333333   \n",
      "98             99  Influencer_99             9.39             55.666667   \n",
      "\n",
      "    Content_Match_Score  Sentiment_Score  Adjusted_Fraud_Score  Matching_Score  \n",
      "94                  100             81.4                    60       63.152000  \n",
      "9                   100             89.3                    10       60.824000  \n",
      "88                  100             78.9                    90       58.702000  \n",
      "5                   100             89.9                    80       58.265333  \n",
      "84                  100             74.9                     0       57.898667  \n",
      "0                   100             61.8                    90       56.207333  \n",
      "87                  100             82.4                    60       56.165333  \n",
      "66                  100             88.3                    50       55.977333  \n",
      "71                  100             60.1                    90       55.401333  \n",
      "98                  100             93.9                    40       54.818667  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate Audience Match Score\n",
    "def calculate_audience_match_score(row):\n",
    "    # Brand's target audience\n",
    "    target_age_range = (18, 35)\n",
    "    target_gender = {'Female': 60, 'Male': 40}\n",
    "    target_locations = ['USA', 'UK', 'Canada']\n",
    "\n",
    "    # Extract influencer's audience demographics\n",
    "    influencer_age_range = tuple(map(int, row['Audience_Age'].split('-')))\n",
    "    influencer_gender = {'Female': row['Female_Percentage'], 'Male': row['Male_Percentage']}\n",
    "    influencer_location = row['Audience_Location']\n",
    "\n",
    "    # Calculate age match\n",
    "    age_match = 1 if target_age_range[0] <= influencer_age_range[0] and influencer_age_range[1] <= target_age_range[1] else 0\n",
    "\n",
    "    # Calculate gender match\n",
    "    gender_match = sum(min(target_gender[g], influencer_gender.get(g, 0)) for g in target_gender) / 100\n",
    "\n",
    "    # Calculate location match\n",
    "    location_match = 1 if influencer_location in target_locations else 0\n",
    "\n",
    "    # Combine scores (equal weights for age, gender, and location)\n",
    "    audience_match_score = (age_match + gender_match + location_match) / 3 * 100\n",
    "    return audience_match_score\n",
    "\n",
    "# Apply the function to calculate Audience Match Score\n",
    "df['Audience_Match_Score'] = df.apply(calculate_audience_match_score, axis=1)\n",
    "\n",
    "# Calculate Content Match Score\n",
    "def calculate_content_match_score(row):\n",
    "    # Brand's target niches\n",
    "    target_niches = ['Fashion', 'Tech', 'Fitness']\n",
    "\n",
    "    # Check if the influencer's niche matches the brand's target niches\n",
    "    if row['Niche'] in target_niches:\n",
    "        return 100  # Perfect match\n",
    "    else:\n",
    "        return 0  # No match\n",
    "\n",
    "# Apply the function to calculate Content Match Score\n",
    "df['Content_Match_Score'] = df.apply(calculate_content_match_score, axis=1)\n",
    "\n",
    "# Option 1: Create a placeholder Sentiment Score based on engagement\n",
    "# This is temporary until you have actual sentiment data\n",
    "df['Sentiment_Score'] = df['Engagement_Rate'] * 10  # Scaling up engagement as a proxy\n",
    "\n",
    "# Adjust Fraud Score\n",
    "df['Adjusted_Fraud_Score'] = 100 - (df['Fraud_Score'] * 10)  # Scale from 0-100 since Fraud_Score is 1-10\n",
    "\n",
    "# Calculate Matching Score\n",
    "df['Matching_Score'] = (\n",
    "    df['Engagement_Rate'] * 0.30 +\n",
    "    df['Audience_Match_Score'] * 0.25 +\n",
    "    df['Content_Match_Score'] * 0.20 +\n",
    "    df['Sentiment_Score'] * 0.15 +\n",
    "    df['Adjusted_Fraud_Score'] * 0.10\n",
    ")\n",
    "\n",
    "# Display the results with all components for verification\n",
    "print(df[['Influencer_ID', 'Name', 'Engagement_Rate', 'Audience_Match_Score', \n",
    "         'Content_Match_Score', 'Sentiment_Score', 'Adjusted_Fraud_Score', \n",
    "         'Matching_Score']].sort_values(by='Matching_Score', ascending=False).head(10))\n",
    "\n",
    "# If you want to save the results\n",
    "df.to_csv('influencer_matching_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampled target variable distribution:\n",
      "Success\n",
      "1    91\n",
      "0    91\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Accuracy: 1.0\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        37\n",
      "   macro avg       1.00      1.00      1.00        37\n",
      "weighted avg       1.00      1.00      1.00        37\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  0]\n",
      " [ 0 18]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('influencer_matching_scores.csv')\n",
    "\n",
    "# Simulate the target variable based on Matching_Score\n",
    "df['Success'] = df['Matching_Score'].apply(lambda x: 1 if x >= 55 else 0)\n",
    "\n",
    "# Save the dataset with the Success column\n",
    "df.to_csv('influencer_matching_scores.csv', index=False)\n",
    "\n",
    "# Features (X) and target variable (y)\n",
    "X = df[['Engagement_Rate', 'Audience_Match_Score', 'Content_Match_Score', 'Sentiment_Score', 'Adjusted_Fraud_Score']]\n",
    "y = df['Success']\n",
    "\n",
    "# Apply Random Oversampling to balance the dataset\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Check the distribution of the resampled target variable\n",
    "print(\"Resampled target variable distribution:\")\n",
    "print(y_resampled.value_counts())\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "0    91\n",
      "1     9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Success'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entrova",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
